install.packages("tibble")
library(car)      # needed for Variance Inflation Factor calculation
library(ggplot2)
install.packages("scales")
library(corrplot)
rm(list=ls())
library(reshape) # needed for melt()
library(rjags)
library(xtable)
library(coda)
library(gdata)    # needed for drop.levels()
library(car)      # needed for Variance Inflation Factor calculation
library(ggplot2)
library(corrplot)
install.packages("colorspace")
library(ggplot2)
install.packages("lazyeval")
library(ggplot2)
rm(list=ls())
library(reshape) # needed for melt()
library(rjags)
library(xtable)
library(coda)
library(gdata)    # needed for drop.levels()
library(car)      # needed for Variance Inflation Factor calculation
library(ggplot2)
library(corrplot)
install.packages("ape")
install.packages("devtools")
install.packages("ggplot2")
install.packages("lavaan")
install.packages("lme4")
install.packages("lmerTest")
install.packages("ncf")
install.packages("nlme")
install.packages("plyr")
install.packages("sp")
library(devtools)
#install_github("jslefche/piecewiseSEM@2.0")
install.packages("piecewiseSEM")
# Load required libraries
library(piecewiseSEM)
# Load required libraries
library(piecewiseSEM)
#install_github("jslefche/piecewiseSEM@2.0")
install.packages("piecewiseSEM")
install.packages("nloptr")
# Load required libraries
library(piecewiseSEM)
# Generate random data
set.seed(1)
data <- data.frame(x1 = rnorm(100))
mean(data$x1)
?rnorm
data$x2 <- data$x1 + runif(100, 0, 3)
data$y1 <- data$x2 + runif(100, 0, 6)
data$y2 <- data$x2 + runif(100, 0, 9)
# Standardized coefficients: Bxy * sd(x) / sd(y)
mod <- lm(y2 ~ y1, data)
summary(mod)
stdCoefs(mod)$Estimate
?stdCoefs
stdCoefs(mod)$Std.Estimate
stdCoefs(mod)
BetaStd <- stdCoefs(mod)$Estimate * sd(data$y1) / sd(data$y2)
BetaStd; stdCoefs(mod)$Std.Estimate
# Estimated automatically if you scale data beforehand
data.scaled <- as.data.frame(apply(data, 2, scale))
mod2 <- lm(y2 ~ y1, data.scaled)
stdCoefs(mod2)$Estimate; stdCoefs(mod2)$Std.Estimate
head(data)
head(data.scaled)
cor(data[,-4])
cor(data.scaled[,-4])
cor(data[, -2])
# Path 1
mody1.x1 <- lm(y1 ~ x1, data)
mody1.x1
stdCoefs(mody1.x1)$Std.Estimate; cor(data[, c("y1", "x1")])[2, 1]
cor(data[, c("y1", "x1")])
# Path 2
mody2.y1 <- lm(y2 ~ y1, data)
stdCoefs(mody2.y1)$Std.Estimate; cor(data[, c("y2", "y1")])[2, 1]
stdCoefs(mody1.x1)$Std.Estimate * stdCoefs(mody2.y1)$Std.Estimate; cor(data[, c("y2", "x1")])[2, 1]
0.44*0.266
0.44*0.258
# Path 1
mody2.x1 <- lm(y2 ~ y1 + x1, data)
stdCoefs(mody2.x1)[2, 8]
stdCoefs(mody2.x1)
gammay2.x1 <- (cor(data$y2, data$x1) - (cor(data$y2, data$y1) * cor(data$y1, data$x1))) /
(1 - cor(data$y1, data$x1) ^ 2)
stdCoefs(mody2.x1)[2, 8]; gammay2.x1
0.44*0.26
0.1144+gammay2.x1
gammay2.y1 <- (cor(data$y2, data$y1) - (cor(data$y2, data$x1) * cor(data$y1, data$x1))) /
(1 - cor(data$y1, data$x1) ^ 2)
stdCoefs(mody2.x1)[1, 8]; gammay2.y1
stdCoefs(mody2.x1)
0.44*0.15
summary(mody2.x1)$r.squared
# Path 1
(zetay2.x1 <- 1 - summary(mody2.x1)$r.squared)
sqrt(zetay2.x1)
# Path 1
(zetay2.x1 <- 1 - summary(mody2.x1)$r.squared)
summary(mody2.x1)
summary(mody1.x1)
# Get residual correlation (must already scaled data)
mody2.x1 <- lm(y2 ~ x1, data)
summary(mody2.x1)
mody1.x1 <- lm(y1 ~ x1, data)
(zetay1 = sqrt(1 - summary(mody1.x1)$r.squared))
(pcor <- cor(
# effect of x1 on y2
resid(mody2.x1),
# effect of x1 on y1
resid(mody1.x1)
))
?resid
resid(mody2.x1)
(pcor <- cor(
# effect of x1 on y2
resid(mody2.x1),
# effect of x1 on y1
resid(mody1.x1)
))
stdCoefs(mody2.x1)$Std.Estimate * stdCoefs(mody1.x1)$Std.Estimate +
zetay2 *
pcor *
zetay1; cor(data$y1, data$y2)
(zetay2 = sqrt(1 - summary(mody2.x1)$r.squared))
mody1.x1 <- lm(y1 ~ x1, data)
(zetay1 = sqrt(1 - summary(mody1.x1)$r.squared))
(pcor <- cor(
# effect of x1 on y2
resid(mody2.x1),
# effect of x1 on y1
resid(mody1.x1)
))
stdCoefs(mody2.x1)$Std.Estimate * stdCoefs(mody1.x1)$Std.Estimate +
zetay2 *
pcor *
zetay1; cor(data$y1, data$y2)
mody2 <- lm(y2 ~ x1 + y1, data)
mody2
stdCoefs(mody2)
stdCoefs(mody2)$Std.Estimate[1]
(stdCoefs(mody1)$Std.Estimate
stdCoefs(mody1)$Std.Estimate
stdCoefs(mody1)$Std.Estimate
mody1 <- lm(y1 ~ x1, data)
stdCoefs(mody1)$Std.Estimate
stdCoefs(mody2)
0.25+0.44*0.15
0.15+0.44*0.25
install.packages("ggdag")
library(ggdag)
?dagify
?ggdag
wakatobi_DAG<-dagify(biomass~coralcover + complexity + population + localCatch + internationalCatch + error,
labels = "biomass" = "UVC\nFish Biomass",
"coralcover" = "Coral\nCover",
"complexity" = "Habitat\nComplexity",
"population" = "Human Population\nDensity",
"localCatch" = "Local Market\nCatch",
"internationalCatch" = "International Market\nCatch",
"error" = "Error")
ggdag(wakatobi_DAG, text=FALSE, use_labels="label")
wakatobi_DAG<-dagify(biomass~coralcover + complexity + population + localCatch + internationalCatch + error,
labels = c("biomass" = "UVC\nFish Biomass",
"coralcover" = "Coral\nCover",
"complexity" = "Habitat\nComplexity",
"population" = "Human Population\nDensity",
"localCatch" = "Local Market\nCatch",
"internationalCatch" = "International Market\nCatch",
"error" = "Error"))
ggdag(wakatobi_DAG, text=FALSE, use_labels="label")
install.packages("jsonlite")
library(ggdag)
wakatobi_DAG<-dagify(biomass~coralcover + complexity + population + localCatch + internationalCatch + error,
labels = c("biomass" = "UVC\nFish Biomass",
"coralcover" = "Coral\nCover",
"complexity" = "Habitat\nComplexity",
"population" = "Human Population\nDensity",
"localCatch" = "Local Market\nCatch",
"internationalCatch" = "International Market\nCatch",
"error" = "Error"))
ggdag(wakatobi_DAG, text=FALSE, use_labels="label")
install.packages("semPlot")
# SEM diagram:
library(semPlot)
install.packages("DiagrammeR")
if(!requireNamespace("devtools")) install.packages("devtools")
devtools::install_github("dkahle/ggmap", ref = "tidyup", force=TRUE)
#Load the library
library("ggmap")
#Set your API Key
ggmap::register_google(key = "AIzaSyBuvn8zwc5UPfMBQykn0dcOOwjCZ--WHLs")
rm(list=ls())
# Load the relevant libraries - do this every time
library(lubridate)
library(ggplot2)
library(dplyr)
library(data.table)
library(ggrepel)
library(tidyverse)
#Get the latest Install of ggmap
#if(!requireNamespace("devtools")) install.packages("devtools")
#devtools::install_github("dkahle/ggmap", ref = "tidyup", force=TRUE)
#Load the ggmap library
library(ggmap)
#Set your API Key
ggmap::register_google(key = "AIzaSyBuvn8zwc5UPfMBQykn0dcOOwjCZ--WHLs")
install.packages("lubridate")
install.packages("tidyverse")
rm(list=ls())
# Load the relevant libraries - do this every time
library(lubridate)
library(ggplot2)
library(dplyr)
library(data.table)
library(ggrepel)
library(tidyverse)
#Get the latest Install of ggmap
#if(!requireNamespace("devtools")) install.packages("devtools")
#devtools::install_github("dkahle/ggmap", ref = "tidyup", force=TRUE)
#Load the ggmap library
library(ggmap)
#Set your API Key
ggmap::register_google(key = "AIzaSyBuvn8zwc5UPfMBQykn0dcOOwjCZ--WHLs")
?version
R.Version()
?tempfile
temp <- tempfile(fileext = ".zip")
download.file("https://drive.google.com/uc?export=download&id=1R9oTFUBDpIGlyr5uLB2l225MiL3hjg83",
temp)
# URL above should be the "download" URL which can be obtained from modifying the shared link. See: https://www.labnol.org/internet/direct-links-for-google-drive/28356/
out <- unzip(temp, exdir = tempdir())
temp <- tempfile(fileext = ".csv")
download.file("https://drive.google.com/uc?export=download&id=1R9oTFUBDpIGlyr5uLB2l225MiL3hjg83",
temp)
# URL above should be the "download" URL which can be obtained from modifying the shared link. See: https://www.labnol.org/internet/direct-links-for-google-drive/28356/
out <- unzip(temp, exdir = tempdir())
out<-download.file("https://drive.google.com/uc?export=download&id=1R9oTFUBDpIGlyr5uLB2l225MiL3hjg83",
temp)
bank <- read.csv(out)
rm(out)
temp <- tempfile(fileext = ".csv")
download.file("https://drive.google.com/uc?export=download&id=1R9oTFUBDpIGlyr5uLB2l225MiL3hjg83",
temp)
# URL above should be the "download" URL which can be obtained from modifying the shared link. See: https://www.labnol.org/internet/direct-links-for-google-drive/28356/
out <- unzip(temp, exdir = tempdir())
temp <- tempfile(fileext = ".zip")
download.file("https://drive.google.com/uc?export=download&id=1R9oTFUBDpIGlyr5uLB2l225MiL3hjg83",
temp)
# URL above should be the "download" URL which can be obtained from modifying the shared link. See: https://www.labnol.org/internet/direct-links-for-google-drive/28356/
out <- unzip(temp, exdir = tempdir())
install.packages("googledrive")
rm(list=ls())
library(googledrive)
temp <- tempfile(fileext = ".zip")
download.file("https://drive.google.com/uc?export=download&id=1R9oTFUBDpIGlyr5uLB2l225MiL3hjg83",
temp)
temp <- tempfile(fileext = ".zip")
dl <- drive_download(
as_id("1R9oTFUBDpIGlyr5uLB2l225MiL3hjg83"), path = temp, overwrite = TRUE)
rm(list=ls())
library(googledrive)
temp <- tempfile(fileext = ".zip")
dl <- drive_download(
as_id("1R9oTFUBDpIGlyr5uLB2l225MiL3hjg83"), path = temp, overwrite = TRUE)
out <- unzip(temp, exdir = tempdir())
out <- unzip(dl, exdir = tempdir())
temp <- tempfile(fileext = ".csv")
dl <- drive_download(
as_id("1R9oTFUBDpIGlyr5uLB2l225MiL3hjg83"), path = temp, overwrite = TRUE)
out <- unzip(temp, exdir = tempdir())
bank <- read.csv(out)
bank <- read.csv(dl)
rm(list=ls())
library(googledrive)
# Download raw data files from SHERA google drive folder
temp <- tempfile(fileext = ".zip")
dl <- drive_download(
as_id("1R9oTFUBDpIGlyr5uLB2l225MiL3hjg83"), path = temp, overwrite = TRUE)
out <- unzip(temp, exdir = tempdir())
bank <- read.csv(dl)
rm(list=ls())
library(googledrive)
rm(list=ls())
library(googledrive)
# Download raw data files from SHERA google drive folder
# Will require you to sign into Google account and grant permission to tidyverse for access
drive_download("Wakatobi-fish-data_041119.csv", overwrite=TRUE)  # saves file locally; overwrite in case you've downloaded it before and want the most up-to-date
landings<-read.csv("Wakatobi-fish-data_041119.csv", header=T, stringsAsFactors = FALSE, strip.white = TRUE)
drive_download("Wakatobi-trip-data_041119.csv", overwrite=TRUE)
trips<-read.csv("Wakatobi-trip-data_041119.csv", header=T, stringsAsFactors = FALSE, strip.white = TRUE)
dim(landings)
dim(trips)
mergecol<-names(landings)[names(landings) %in% names(trips)]
tempdat<-merge(landings, trips, by=mergecol)
rm(list=ls())
library(googledrive)
# Download raw data files from SHERA google drive folder
# Will require you to sign into Google account and grant permission to tidyverse for access
drive_download("Wakatobi-fish-data_041119.csv", overwrite=TRUE)  # saves file locally; overwrite in case you've downloaded it before and want the most up-to-date
library(googledrive)
# Download raw data files from SHERA google drive folder
# Will require you to sign into Google account and grant permission to tidyverse for access
drive_download("Wakatobi-fish-data_041119.csv", overwrite=TRUE)  # saves file locally; overwrite in case you've downloaded it before and want the most up-to-date
# Download raw data files from SHERA google drive folder
# Will require you to sign into Google account and grant permission to tidyverse for access
gs_auth()
rm(list=ls())
library(googledrive)
gs_user()
?drive_auth
# Download raw data files from SHERA google drive folder
# Will require you to sign into Google account and grant permission to tidyverse for access
drive_auth()
drive_download("Wakatobi-fish-data_041119.csv", overwrite=TRUE)  # saves file locally; overwrite in case you've downloaded it before and want the most up-to-date
landings<-read.csv("Wakatobi-fish-data_041119.csv", header=T, stringsAsFactors = FALSE, strip.white = TRUE)
drive_download("Wakatobi-trip-data_041119.csv", overwrite=TRUE)
trips<-read.csv("Wakatobi-trip-data_041119.csv", header=T, stringsAsFactors = FALSE, strip.white = TRUE)
dim(landings)
dim(trips)
mergecol<-names(landings)[names(landings) %in% names(trips)]
tempdat<-merge(landings, trips, by=mergecol)
head(tempdat)
dim(tempdat)
21285-19288
?merge
tempdat<-merge(landings, trips, by=mergecol, all=TRUE)
dim(tempdat)
tempdat<-merge(landings, trips, by=mergecol)
mergecol
table(landings$trip_id)
table(trips$trip_id)
# Questions for Melati?
# table(trips$trip_id) # why are some trip_IDs not unique?
tempdat[tempdat$trip_id=="1 11 ACER + DULETES",]
tempdat[tempdat$Fish_name_p=="Kuami",]
tempdat[tempdat$Fish_name_p=="Kumai",]
dim(tempdat[tempdat$Fish_name_p=="Kumai",])
# Questions for Melati?
# table(trips$trip_id) # why are some trip_IDs not unique?
dim(tempdat[tempdat$trip_id=="1 11 ACER + DULETES",])
# Questions for Melati?
# table(trips$trip_id) # why are some trip_IDs not unique?
tempdat[tempdat$trip_id=="1 11 ACER + DULETES",]
rm(list=ls())
library(googledrive)
### GET DATA AND CREATE SUMMARY TABLES
# Download raw data files from SHERA google drive folder
drive_auth() # Will require you to sign into Google account and grant permission to tidyverse for access
#drive_download("Wakatobi-landings_041119_FISH.csv", type="csv", overwrite=TRUE)  # saves file locally; overwrite in case you've downloaded it before and want the most up-to-date
#file id: 1_71pviN-qsSmvAZAgQMCQIqkEXpKTPcd
#Use File ID method: more specific file identification
drive_download(as_id("1_71pviN-qsSmvAZAgQMCQIqkEXpKTPcd"), overwrite=TRUE) # Saves file to working directory
landings<-read.csv("Wakatobi-landings_041119_FISH.csv", header=T, stringsAsFactors = FALSE, strip.white = TRUE)
#drive_download("Wakatobi-landings_041119_TRIP.csv", overwrite=TRUE)
#file id: 1lVYpdmf8i0BZYbK5iQxXn2eFR1klxWbC
drive_download(as_id("1lVYpdmf8i0BZYbK5iQxXn2eFR1klxWbC"), overwrite=TRUE)
trips<-read.csv("Wakatobi-landings_041119_TRIP.csv", header=T, stringsAsFactors = FALSE, strip.white = TRUE)
head(trips)
log10*29611
log10(29611)
-0.42+(0.742*log10(29611))
?invlog
?exp
exp(2.8978)
e
exp
10^2.89
rm(list=ls())
rm(list=ls())
library(googledrive)
### GET DATA AND CREATE SUMMARY TABLES
# Download raw data files from SHERA google drive folder
drive_auth() # Will require you to sign into Google account and grant permission to tidyverse for access
#drive_download("Wakatobi-landings_041119_FISH.csv", type="csv", overwrite=TRUE)  # saves file locally; overwrite in case you've downloaded it before and want the most up-to-date
#file id: 1_71pviN-qsSmvAZAgQMCQIqkEXpKTPcd
#Use File ID method: more specific file identification
drive_download(as_id("1_71pviN-qsSmvAZAgQMCQIqkEXpKTPcd"), overwrite=TRUE) # Saves file to working directory
landings<-read.csv("Wakatobi-landings_041119_FISH.csv", header=T, stringsAsFactors = FALSE, strip.white = TRUE)
#drive_download("Wakatobi-landings_041119_TRIP.csv", overwrite=TRUE)
#file id: 1lVYpdmf8i0BZYbK5iQxXn2eFR1klxWbC
drive_download(as_id("1lVYpdmf8i0BZYbK5iQxXn2eFR1klxWbC"), overwrite=TRUE)
trips<-read.csv("Wakatobi-landings_041119_TRIP.csv", header=T, stringsAsFactors = FALSE, strip.white = TRUE)
unique(trips$fishing_grnd1)
sort(unique(trips$fishing_grnd1))
write.csv(sort(unique(trips$fishing_grnd1)), "fishing_grounds.csv", quote=FALSE)
write.csv(sort(unique(trips$fishing_grnd2)), "fishing_grounds.csv", quote=FALSE)
write.csv(sort(unique(trips$fishing_grnd2)), "fishing_grounds1.csv", quote=FALSE)
write.csv(sort(unique(trips$fishing_grnd1)), "fishing_grounds1.csv", quote=FALSE)
write.csv(sort(unique(trips$fishing_grnd2)), "fishing_grounds2.csv", quote=FALSE)
head(trips)
trips2<-unique(trips)
table(trips$trip_id)
rm(list=ls())
library(googledrive)
### GET DATA AND CREATE SUMMARY TABLES
# Download raw data files from SHERA google drive folder
drive_auth() # Will require you to sign into Google account and grant permission to tidyverse for access
#drive_download("Wakatobi-landings_041119_FISH.csv", type="csv", overwrite=TRUE)  # saves file locally; overwrite in case you've downloaded it before and want the most up-to-date
#file id: 1_71pviN-qsSmvAZAgQMCQIqkEXpKTPcd
#Use File ID method: more specific file identification
drive_download(as_id("1_71pviN-qsSmvAZAgQMCQIqkEXpKTPcd"), overwrite=TRUE) # Saves file to working directory
landings<-read.csv("Wakatobi-landings_041119_FISH.csv", header=T, stringsAsFactors = FALSE, strip.white = TRUE)
#drive_download("Wakatobi-landings_041119_TRIP.csv", overwrite=TRUE)
#file id: 1lVYpdmf8i0BZYbK5iQxXn2eFR1klxWbC
drive_download(as_id("1lVYpdmf8i0BZYbK5iQxXn2eFR1klxWbC"), overwrite=TRUE)
trips<-read.csv("Wakatobi-landings_041119_TRIP.csv", header=T, stringsAsFactors = FALSE, strip.white = TRUE)
unique(trips$trip_id)
sort(unique(trips$trip_id))
write.csv(sort(unique(trips$trip_id)), quote=FALSE)
write.csv(sort(unique(trips$trip_id)), "trips.csv" quote=FALSE)
write.csv(sort(unique(trips$trip_id)), "trips.csv", quote=FALSE)
rm(list=ls())
library(googledrive)
### GET DATA AND CREATE SUMMARY TABLES
# Download raw data files from SHERA google drive folder
drive_auth() # Will require you to sign into Google account and grant permission to tidyverse for access
#drive_download("Wakatobi-landings_041119_FISH.csv", type="csv", overwrite=TRUE)  # saves file locally; overwrite in case you've downloaded it before and want the most up-to-date
#file id: 1_71pviN-qsSmvAZAgQMCQIqkEXpKTPcd
#Use File ID method: more specific file identification
drive_download(as_id("1_71pviN-qsSmvAZAgQMCQIqkEXpKTPcd"), overwrite=TRUE) # Saves file to working directory
landings<-read.csv("Wakatobi-landings_041119_FISH.csv", header=T, stringsAsFactors = FALSE, strip.white = TRUE)
# NOTES on cleaning TRIP IDs:
# A: Most duplicate trip IDs were identical rows of data: Deleted duplicates
# B: For duplicate trip IDs that were non-unique:
# try to coroborate data with raw data sheets
# use date to track down raw data file
# if this doesn't work, search by "captain name"
# if can't find raw data sheet, keep all trips for now
# Changes:
# 1 25 SIDDENG - kept data row with "bulawis" as dominant species
# C: Could not find raw data sheets for the following trips:
# 1 11 DAHLAN
# 1 11 ACER + DULETES - couldn't find raw data sheet !!!! (still need to address this)
# 11 20 BAGON - couldn't find raw data sheet !!!! (still need to address this)
# D: Deleted all trip IDs with missing dates
# Checked all of these and found them to be duplicate rows after adding dates to tripID
# SAVED AS "Wakatobi-landings_062019_TRIP-CLEAN.csv"
#drive_download("Wakatobi-landings_041119_TRIP.csv", overwrite=TRUE)
#file id: 1lVYpdmf8i0BZYbK5iQxXn2eFR1klxWbC
drive_download(as_id("1lVYpdmf8i0BZYbK5iQxXn2eFR1klxWbC"), overwrite=TRUE)
trips<-read.csv("Wakatobi-landings_062019_TRIP-CLEAN.csv", header=T, stringsAsFactors = FALSE, strip.white = TRUE)
rm(list=ls())
library(googledrive)
### GET DATA AND CREATE SUMMARY TABLES
# Download raw data files from SHERA google drive folder
drive_auth() # Will require you to sign into Google account and grant permission to tidyverse for access
#drive_download("Wakatobi-landings_041119_FISH.csv", type="csv", overwrite=TRUE)  # saves file locally; overwrite in case you've downloaded it before and want the most up-to-date
#file id: 1_71pviN-qsSmvAZAgQMCQIqkEXpKTPcd
#Use File ID method: more specific file identification
drive_download(as_id("1_71pviN-qsSmvAZAgQMCQIqkEXpKTPcd"), overwrite=TRUE) # Saves file to working directory
landings<-read.csv("Wakatobi-landings_041119_FISH.csv", header=T, stringsAsFactors = FALSE, strip.white = TRUE)
#drive_download("Wakatobi-landings_041119_TRIP.csv", overwrite=TRUE)
#file id: 1lVYpdmf8i0BZYbK5iQxXn2eFR1klxWbC
drive_download(as_id("1lVYpdmf8i0BZYbK5iQxXn2eFR1klxWbC"), overwrite=TRUE)
trips<-read.csv("Wakatobi-landings_062019_TRIP-CLEAN.csv", header=T, stringsAsFactors = FALSE, strip.white = TRUE)
#drive_download("Wakatobi-landings_041119_TRIP.csv", overwrite=TRUE)
#file id: 1lVYpdmf8i0BZYbK5iQxXn2eFR1klxWbC
drive_download(as_id("1lVYpdmf8i0BZYbK5iQxXn2eFR1klxWbC"), overwrite=TRUE)
trips<-read.csv("Wakatobi-landings_062019_TRIP-CLEAN.csv", header=T, stringsAsFactors = FALSE, strip.white = TRUE)
# CLEANED trips file
drive_download(as_id("1Y-P9JIUWBZy9TMEoetKoimJeQytkVOmU"), overwrite=TRUE)
# CLEANED trips file
drive_download(as_id("P9JIUWBZy9TMEoetKoimJeQytkVOmU"), overwrite=TRUE)
# CLEANED trips file
#file id: 1gL7_gUFYUtETEVDBlNQ3FN7Ddt04AIsP
drive_download(as_id("1gL7_gUFYUtETEVDBlNQ3FN7Ddt04AIsP"), overwrite=TRUE)
trips<-read.csv("Wakatobi-landings_062019_TRIP-CLEAN.csv", header=T, stringsAsFactors = FALSE, strip.white = TRUE)
setwd("~/Analyses/wakatobi")
rm(list=ls())
library(googledrive)
library(dplyr)
### GET DATA AND CREATE SUMMARY TABLES
# Download raw data files from SHERA google drive folder
drive_auth() # Will require you to sign into Google account and grant permission to tidyverse for access
#drive_download("Wakatobi-landings_041119_FISH.csv", type="csv", overwrite=TRUE)  # saves file locally; overwrite in case you've downloaded it before and want the most up-to-date
#file id: 1_71pviN-qsSmvAZAgQMCQIqkEXpKTPcd
#Use File ID method: more specific file identification
drive_download(as_id("1_71pviN-qsSmvAZAgQMCQIqkEXpKTPcd"), overwrite=TRUE) # Saves file to working directory
rm(list=ls())
library(googledrive)
library(dplyr)
# READ IN latest CLEANED fish landings file here:
drive_auth() # Will require you to sign into Google account and grant permission to tidyverse for access
drive_download(as_id("10-ERWTJI2SZS0ljP9noprFhmKU0sjDBN"), overwrite=TRUE) # Saves file to working directory
landings<-read.csv("Wakatobi-landings_061819_FISH.csv")
file.remove("Wakatobi-landings_061819_FISH.csv")
# READ IN latest CLEANED trips file here:
#file id: 1gL7_gUFYUtETEVDBlNQ3FN7Ddt04AIsP
drive_download(as_id("1gL7_gUFYUtETEVDBlNQ3FN7Ddt04AIsP"), overwrite=TRUE)
trips<-read.csv("Wakatobi-landings_062019_TRIP.csv", header=T, stringsAsFactors = FALSE, strip.white = TRUE)
file.remove("Wakatobi-landings_062019_TRIP.csv")
write.csv(as.data.frame(table(trips$trip_id)), "table_tripID.csv")
rm(list=ls())
library(googledrive)
library(dplyr)
drive_auth() # Will require you to sign into Google account and grant permission to tidyverse for access
drive_download(as_id("10-ERWTJI2SZS0ljP9noprFhmKU0sjDBN"), overwrite=TRUE) # Saves file to working directory
landings<-read.csv("Wakatobi-landings_061819_FISH.csv")
file.remove("Wakatobi-landings_061819_FISH.csv")
drive_download(as_id("1gL7_gUFYUtETEVDBlNQ3FN7Ddt04AIsP"), overwrite=TRUE)
trips<-read.csv("Wakatobi-landings_062019_TRIP.csv", header=T, stringsAsFactors = FALSE, strip.white = TRUE)
file.remove("Wakatobi-landings_062019_TRIP.csv")
table(trips$trip_id)
sort(table(trips$trip_id))
