species("Acanthurus mata")
install.packages("rich")
data(ef)
library(rich)
data(ef)
head(ef)
?ef
?BCI
install.packages("mmSAR")
plots <- array(dim=c(5,20))
rm(list=ls())
plots <- array(dim=c(5,20))
species <- c(letters[1:20])
probs <- numeric(20)
probs[1:8] <- runif(8, 0, 0.1)
for(i in 9:20){
probs[i] <- runif(1, 0, 1-sum(probs[1:i-1]))
}
head(probs)
for(i in 1:20){
plots[,i] <- sample(species, size=5, replace=T, prob=probs)
}
SAR.mat <- array(dim=c(20,20))
str(SAR.mat)
SAR.mat
for(j in 1:20){
for(i in 1:20){
plot.index <- sample(1:20, j, replace=F)
SAR.plot <- c(plots[,plot.index])
SAR.mat[i,j] <- length(unique(SAR.plot))
}
}
SAR.mat
areas <- 1:20
means <- apply(SAR.mat, MARGIN=2, mean)
lower.95 <- apply(SAR.mat, MARGIN=2, function(x) quantile(x, 0.025))
upper.95 <- apply(SAR.mat, MARGIN=2, function(x) quantile(x, 0.975))
par(mar=c(4,4,1,1)+0.2)
plot(areas, means, type='n', xlab=expression('Area '*(m^-2)),
ylab='Species Richness', cex.lab=1.2,
ylim=c(0,12))
polygon(x=c(areas, rev(areas)),
y=c(lower.95, rev(upper.95)),
col='grey90')
lines(areas, means, lwd=2)
means
areas
SAR.mod <- lm(log(means) ~ log(areas))
summary(SAR.mod)
curve(exp(coef(SAR.mod)[1])*x^coef(SAR.mod)[2], add=T, from=0, to=20, col='red', lwd=2)
SAR.nls <- nls(means ~ a*areas^b,
start=list('a'=exp(coef(SAR.mod)[1]),
'b'=coef(SAR.mod)[2]))
curve(coef(SAR.nls)[1]*x^coef(SAR.nls)[2], add=T, from=0, to=20, col='blue', lwd=2)
legend('topleft', lty=1, col=c('black', 'red', 'blue'),
legend=c('Median Species Richness', 'Linear Model Fit', 'Nonlinear Model Fit'),
cex=0.8,
bty='n')
rm(list=ls())
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies=TRUE)
fx <- inline::cxxfunction( signature(x = "integer", y = "numeric" ) , '
return ScalarReal( INTEGER(x)[0] * REAL(y)[0] ) ;
' )
fx( 2L, 5 ) # should be 10
library(rstan)
install.packages("shinystan")
install.packages("bayesplot")
install.packages("loo")
rm(list=ls())
install.packages("lavaan")
library(lavaan)
R.version()
R.Version()
example(cfa)
library(lavaan)
rm(list=ls())
library(lavaan)
library(lavaan)
install.packages('devtools') #assuming it is not already installed
library(devtools)
install_github('andreacirilloac/updateR')
library(updateR)
updateR(admin_password = 'ana0cap0')
install.packages(as.vector(needed_packages))
R.Version()
library(lavaan)
lavaan()
library(lavaan)
.Library()
.Library
find.package()
installed.packages()
library(lavaan)
install.packages("lavaan")
library(lavaan)
install.packages("mnormt")
library(lavaan)
install.packages("lavaan")
library(lavaan)
install.packages("pbivnorm")
library(lavaan)
?HolzingerSwineford1939
?cfa
dm(HolzingerSwineford1939)
dim(HolzingerSwineford1939)
head(HolzingerSwineford1939)
?PoliticalDemocracy
head(PoliticalDemocracy)
install.packages("piecewiseSEM")
install.packages("lme4")
install.packages("piecewiseSEM")
install.packages("minqa")
install.packages("piecewiseSEM")
install.packages("Rcpp")
install.packages("piecewiseSEM")
update.packages()
rm(list=ls())
library(reshape) # needed for melt()
install.packages("plyr")
rm(list=ls())
library(reshape) # needed for melt()
library(rjags)
library(xtable)
library(coda)
library(gdata)    # needed for drop.levels()
library(car)      # needed for Variance Inflation Factor calculation
install.packages("rlang")
library(car)      # needed for Variance Inflation Factor calculation
install.packages("tibble")
library(car)      # needed for Variance Inflation Factor calculation
library(ggplot2)
install.packages("scales")
library(corrplot)
rm(list=ls())
library(reshape) # needed for melt()
library(rjags)
library(xtable)
library(coda)
library(gdata)    # needed for drop.levels()
library(car)      # needed for Variance Inflation Factor calculation
library(ggplot2)
library(corrplot)
install.packages("colorspace")
library(ggplot2)
install.packages("lazyeval")
library(ggplot2)
rm(list=ls())
library(reshape) # needed for melt()
library(rjags)
library(xtable)
library(coda)
library(gdata)    # needed for drop.levels()
library(car)      # needed for Variance Inflation Factor calculation
library(ggplot2)
library(corrplot)
install.packages("ape")
install.packages("devtools")
install.packages("ggplot2")
install.packages("lavaan")
install.packages("lme4")
install.packages("lmerTest")
install.packages("ncf")
install.packages("nlme")
install.packages("plyr")
install.packages("sp")
library(devtools)
#install_github("jslefche/piecewiseSEM@2.0")
install.packages("piecewiseSEM")
# Load required libraries
library(piecewiseSEM)
# Load required libraries
library(piecewiseSEM)
#install_github("jslefche/piecewiseSEM@2.0")
install.packages("piecewiseSEM")
install.packages("nloptr")
# Load required libraries
library(piecewiseSEM)
# Generate random data
set.seed(1)
data <- data.frame(x1 = rnorm(100))
mean(data$x1)
?rnorm
data$x2 <- data$x1 + runif(100, 0, 3)
data$y1 <- data$x2 + runif(100, 0, 6)
data$y2 <- data$x2 + runif(100, 0, 9)
# Standardized coefficients: Bxy * sd(x) / sd(y)
mod <- lm(y2 ~ y1, data)
summary(mod)
stdCoefs(mod)$Estimate
?stdCoefs
stdCoefs(mod)$Std.Estimate
stdCoefs(mod)
BetaStd <- stdCoefs(mod)$Estimate * sd(data$y1) / sd(data$y2)
BetaStd; stdCoefs(mod)$Std.Estimate
# Estimated automatically if you scale data beforehand
data.scaled <- as.data.frame(apply(data, 2, scale))
mod2 <- lm(y2 ~ y1, data.scaled)
stdCoefs(mod2)$Estimate; stdCoefs(mod2)$Std.Estimate
head(data)
head(data.scaled)
cor(data[,-4])
cor(data.scaled[,-4])
cor(data[, -2])
# Path 1
mody1.x1 <- lm(y1 ~ x1, data)
mody1.x1
stdCoefs(mody1.x1)$Std.Estimate; cor(data[, c("y1", "x1")])[2, 1]
cor(data[, c("y1", "x1")])
# Path 2
mody2.y1 <- lm(y2 ~ y1, data)
stdCoefs(mody2.y1)$Std.Estimate; cor(data[, c("y2", "y1")])[2, 1]
stdCoefs(mody1.x1)$Std.Estimate * stdCoefs(mody2.y1)$Std.Estimate; cor(data[, c("y2", "x1")])[2, 1]
0.44*0.266
0.44*0.258
# Path 1
mody2.x1 <- lm(y2 ~ y1 + x1, data)
stdCoefs(mody2.x1)[2, 8]
stdCoefs(mody2.x1)
gammay2.x1 <- (cor(data$y2, data$x1) - (cor(data$y2, data$y1) * cor(data$y1, data$x1))) /
(1 - cor(data$y1, data$x1) ^ 2)
stdCoefs(mody2.x1)[2, 8]; gammay2.x1
0.44*0.26
0.1144+gammay2.x1
gammay2.y1 <- (cor(data$y2, data$y1) - (cor(data$y2, data$x1) * cor(data$y1, data$x1))) /
(1 - cor(data$y1, data$x1) ^ 2)
stdCoefs(mody2.x1)[1, 8]; gammay2.y1
stdCoefs(mody2.x1)
0.44*0.15
summary(mody2.x1)$r.squared
# Path 1
(zetay2.x1 <- 1 - summary(mody2.x1)$r.squared)
sqrt(zetay2.x1)
# Path 1
(zetay2.x1 <- 1 - summary(mody2.x1)$r.squared)
summary(mody2.x1)
summary(mody1.x1)
# Get residual correlation (must already scaled data)
mody2.x1 <- lm(y2 ~ x1, data)
summary(mody2.x1)
mody1.x1 <- lm(y1 ~ x1, data)
(zetay1 = sqrt(1 - summary(mody1.x1)$r.squared))
(pcor <- cor(
# effect of x1 on y2
resid(mody2.x1),
# effect of x1 on y1
resid(mody1.x1)
))
?resid
resid(mody2.x1)
(pcor <- cor(
# effect of x1 on y2
resid(mody2.x1),
# effect of x1 on y1
resid(mody1.x1)
))
stdCoefs(mody2.x1)$Std.Estimate * stdCoefs(mody1.x1)$Std.Estimate +
zetay2 *
pcor *
zetay1; cor(data$y1, data$y2)
(zetay2 = sqrt(1 - summary(mody2.x1)$r.squared))
mody1.x1 <- lm(y1 ~ x1, data)
(zetay1 = sqrt(1 - summary(mody1.x1)$r.squared))
(pcor <- cor(
# effect of x1 on y2
resid(mody2.x1),
# effect of x1 on y1
resid(mody1.x1)
))
stdCoefs(mody2.x1)$Std.Estimate * stdCoefs(mody1.x1)$Std.Estimate +
zetay2 *
pcor *
zetay1; cor(data$y1, data$y2)
mody2 <- lm(y2 ~ x1 + y1, data)
mody2
stdCoefs(mody2)
stdCoefs(mody2)$Std.Estimate[1]
(stdCoefs(mody1)$Std.Estimate
stdCoefs(mody1)$Std.Estimate
stdCoefs(mody1)$Std.Estimate
mody1 <- lm(y1 ~ x1, data)
stdCoefs(mody1)$Std.Estimate
stdCoefs(mody2)
0.25+0.44*0.15
0.15+0.44*0.25
install.packages("ggdag")
library(ggdag)
?dagify
?ggdag
wakatobi_DAG<-dagify(biomass~coralcover + complexity + population + localCatch + internationalCatch + error,
labels = "biomass" = "UVC\nFish Biomass",
"coralcover" = "Coral\nCover",
"complexity" = "Habitat\nComplexity",
"population" = "Human Population\nDensity",
"localCatch" = "Local Market\nCatch",
"internationalCatch" = "International Market\nCatch",
"error" = "Error")
ggdag(wakatobi_DAG, text=FALSE, use_labels="label")
wakatobi_DAG<-dagify(biomass~coralcover + complexity + population + localCatch + internationalCatch + error,
labels = c("biomass" = "UVC\nFish Biomass",
"coralcover" = "Coral\nCover",
"complexity" = "Habitat\nComplexity",
"population" = "Human Population\nDensity",
"localCatch" = "Local Market\nCatch",
"internationalCatch" = "International Market\nCatch",
"error" = "Error"))
ggdag(wakatobi_DAG, text=FALSE, use_labels="label")
install.packages("jsonlite")
library(ggdag)
wakatobi_DAG<-dagify(biomass~coralcover + complexity + population + localCatch + internationalCatch + error,
labels = c("biomass" = "UVC\nFish Biomass",
"coralcover" = "Coral\nCover",
"complexity" = "Habitat\nComplexity",
"population" = "Human Population\nDensity",
"localCatch" = "Local Market\nCatch",
"internationalCatch" = "International Market\nCatch",
"error" = "Error"))
ggdag(wakatobi_DAG, text=FALSE, use_labels="label")
install.packages("semPlot")
# SEM diagram:
library(semPlot)
install.packages("DiagrammeR")
if(!requireNamespace("devtools")) install.packages("devtools")
devtools::install_github("dkahle/ggmap", ref = "tidyup", force=TRUE)
#Load the library
library("ggmap")
#Set your API Key
ggmap::register_google(key = "AIzaSyBuvn8zwc5UPfMBQykn0dcOOwjCZ--WHLs")
rm(list=ls())
# Load the relevant libraries - do this every time
library(lubridate)
library(ggplot2)
library(dplyr)
library(data.table)
library(ggrepel)
library(tidyverse)
#Get the latest Install of ggmap
#if(!requireNamespace("devtools")) install.packages("devtools")
#devtools::install_github("dkahle/ggmap", ref = "tidyup", force=TRUE)
#Load the ggmap library
library(ggmap)
#Set your API Key
ggmap::register_google(key = "AIzaSyBuvn8zwc5UPfMBQykn0dcOOwjCZ--WHLs")
install.packages("lubridate")
install.packages("tidyverse")
rm(list=ls())
# Load the relevant libraries - do this every time
library(lubridate)
library(ggplot2)
library(dplyr)
library(data.table)
library(ggrepel)
library(tidyverse)
#Get the latest Install of ggmap
#if(!requireNamespace("devtools")) install.packages("devtools")
#devtools::install_github("dkahle/ggmap", ref = "tidyup", force=TRUE)
#Load the ggmap library
library(ggmap)
#Set your API Key
ggmap::register_google(key = "AIzaSyBuvn8zwc5UPfMBQykn0dcOOwjCZ--WHLs")
?version
R.Version()
?tempfile
temp <- tempfile(fileext = ".zip")
download.file("https://drive.google.com/uc?export=download&id=1R9oTFUBDpIGlyr5uLB2l225MiL3hjg83",
temp)
# URL above should be the "download" URL which can be obtained from modifying the shared link. See: https://www.labnol.org/internet/direct-links-for-google-drive/28356/
out <- unzip(temp, exdir = tempdir())
temp <- tempfile(fileext = ".csv")
download.file("https://drive.google.com/uc?export=download&id=1R9oTFUBDpIGlyr5uLB2l225MiL3hjg83",
temp)
# URL above should be the "download" URL which can be obtained from modifying the shared link. See: https://www.labnol.org/internet/direct-links-for-google-drive/28356/
out <- unzip(temp, exdir = tempdir())
out<-download.file("https://drive.google.com/uc?export=download&id=1R9oTFUBDpIGlyr5uLB2l225MiL3hjg83",
temp)
bank <- read.csv(out)
rm(out)
temp <- tempfile(fileext = ".csv")
download.file("https://drive.google.com/uc?export=download&id=1R9oTFUBDpIGlyr5uLB2l225MiL3hjg83",
temp)
# URL above should be the "download" URL which can be obtained from modifying the shared link. See: https://www.labnol.org/internet/direct-links-for-google-drive/28356/
out <- unzip(temp, exdir = tempdir())
temp <- tempfile(fileext = ".zip")
download.file("https://drive.google.com/uc?export=download&id=1R9oTFUBDpIGlyr5uLB2l225MiL3hjg83",
temp)
# URL above should be the "download" URL which can be obtained from modifying the shared link. See: https://www.labnol.org/internet/direct-links-for-google-drive/28356/
out <- unzip(temp, exdir = tempdir())
install.packages("googledrive")
rm(list=ls())
library(googledrive)
temp <- tempfile(fileext = ".zip")
download.file("https://drive.google.com/uc?export=download&id=1R9oTFUBDpIGlyr5uLB2l225MiL3hjg83",
temp)
temp <- tempfile(fileext = ".zip")
dl <- drive_download(
as_id("1R9oTFUBDpIGlyr5uLB2l225MiL3hjg83"), path = temp, overwrite = TRUE)
rm(list=ls())
library(googledrive)
temp <- tempfile(fileext = ".zip")
dl <- drive_download(
as_id("1R9oTFUBDpIGlyr5uLB2l225MiL3hjg83"), path = temp, overwrite = TRUE)
out <- unzip(temp, exdir = tempdir())
out <- unzip(dl, exdir = tempdir())
temp <- tempfile(fileext = ".csv")
dl <- drive_download(
as_id("1R9oTFUBDpIGlyr5uLB2l225MiL3hjg83"), path = temp, overwrite = TRUE)
out <- unzip(temp, exdir = tempdir())
bank <- read.csv(out)
bank <- read.csv(dl)
rm(list=ls())
library(googledrive)
# Download raw data files from SHERA google drive folder
temp <- tempfile(fileext = ".zip")
dl <- drive_download(
as_id("1R9oTFUBDpIGlyr5uLB2l225MiL3hjg83"), path = temp, overwrite = TRUE)
out <- unzip(temp, exdir = tempdir())
bank <- read.csv(dl)
rm(list=ls())
library(googledrive)
rm(list=ls())
library(googledrive)
# Download raw data files from SHERA google drive folder
# Will require you to sign into Google account and grant permission to tidyverse for access
drive_download("Wakatobi-fish-data_041119.csv", overwrite=TRUE)  # saves file locally; overwrite in case you've downloaded it before and want the most up-to-date
landings<-read.csv("Wakatobi-fish-data_041119.csv", header=T, stringsAsFactors = FALSE, strip.white = TRUE)
drive_download("Wakatobi-trip-data_041119.csv", overwrite=TRUE)
trips<-read.csv("Wakatobi-trip-data_041119.csv", header=T, stringsAsFactors = FALSE, strip.white = TRUE)
dim(landings)
dim(trips)
mergecol<-names(landings)[names(landings) %in% names(trips)]
tempdat<-merge(landings, trips, by=mergecol)
rm(list=ls())
library(googledrive)
# Download raw data files from SHERA google drive folder
# Will require you to sign into Google account and grant permission to tidyverse for access
drive_download("Wakatobi-fish-data_041119.csv", overwrite=TRUE)  # saves file locally; overwrite in case you've downloaded it before and want the most up-to-date
library(googledrive)
# Download raw data files from SHERA google drive folder
# Will require you to sign into Google account and grant permission to tidyverse for access
drive_download("Wakatobi-fish-data_041119.csv", overwrite=TRUE)  # saves file locally; overwrite in case you've downloaded it before and want the most up-to-date
# Download raw data files from SHERA google drive folder
# Will require you to sign into Google account and grant permission to tidyverse for access
gs_auth()
rm(list=ls())
library(googledrive)
gs_user()
?drive_auth
# Download raw data files from SHERA google drive folder
# Will require you to sign into Google account and grant permission to tidyverse for access
drive_auth()
drive_download("Wakatobi-fish-data_041119.csv", overwrite=TRUE)  # saves file locally; overwrite in case you've downloaded it before and want the most up-to-date
landings<-read.csv("Wakatobi-fish-data_041119.csv", header=T, stringsAsFactors = FALSE, strip.white = TRUE)
drive_download("Wakatobi-trip-data_041119.csv", overwrite=TRUE)
trips<-read.csv("Wakatobi-trip-data_041119.csv", header=T, stringsAsFactors = FALSE, strip.white = TRUE)
dim(landings)
dim(trips)
mergecol<-names(landings)[names(landings) %in% names(trips)]
tempdat<-merge(landings, trips, by=mergecol)
head(tempdat)
dim(tempdat)
21285-19288
?merge
tempdat<-merge(landings, trips, by=mergecol, all=TRUE)
dim(tempdat)
tempdat<-merge(landings, trips, by=mergecol)
mergecol
table(landings$trip_id)
table(trips$trip_id)
# Questions for Melati?
# table(trips$trip_id) # why are some trip_IDs not unique?
tempdat[tempdat$trip_id=="1 11 ACER + DULETES",]
tempdat[tempdat$Fish_name_p=="Kuami",]
tempdat[tempdat$Fish_name_p=="Kumai",]
dim(tempdat[tempdat$Fish_name_p=="Kumai",])
# Questions for Melati?
# table(trips$trip_id) # why are some trip_IDs not unique?
dim(tempdat[tempdat$trip_id=="1 11 ACER + DULETES",])
# Questions for Melati?
# table(trips$trip_id) # why are some trip_IDs not unique?
tempdat[tempdat$trip_id=="1 11 ACER + DULETES",]
setwd("~/Analyses/wakatobi")
cleandist1<-read.csv("data_landings_041119_FISH_checkspelling_dist1.csv")
cleandist1a<-read.csv("data_landings_041119_FISH_checkspelling_dist1a.csv")
cleandist2<-read.csv("data_landings_041119_FISH_checkspelling_dist2.csv")
cleandist2a<-read.csv("data_landings_041119_FISH_checkspelling_dist2a.csv")
table(cleandist1$Fish_name_p)
as.data.frame(table(cleandist1$Fish_name_p))
cleandist1<-read.csv("data_landings_041119_FISH_checkspelling_dist1.csv")
write.csv(as.data.frame(table(cleandist1$Fish_name_p)), "table_cleandist1_FishNames.csv")
cleandist1a<-read.csv("data_landings_041119_FISH_checkspelling_dist1a.csv")
write.csv(as.data.frame(table(cleandist1a$Fish_name_p)), "table_cleandist1a_FishNames.csv")
cleandist2<-read.csv("data_landings_041119_FISH_checkspelling_dist2.csv")
write.csv(as.data.frame(table(cleandist2$Fish_name_p)), "table_cleandist2_FishNames.csv")
cleandist2a<-read.csv("data_landings_041119_FISH_checkspelling_dist2a.csv")
write.csv(as.data.frame(table(cleandist2a$Fish_name_p)), "table_cleandist2a_FishNames.csv")
landings<-cleandist2a
### MERGE fish and trip data
dim(landings)
trips<-read.csv("Wakatobi-landings_041119_TRIP.csv", header=T, stringsAsFactors = FALSE, strip.white = TRUE)
dim(trips)
table(landings$trip_id)
table(trips$trip_id)
write.csv(as.data.frame(table(trips$trip_id)), "table_tripID.csv")
mergecol<-names(landings)[names(landings) %in% names(trips)]
write.csv(as.data.frame(table(trips$trip_id)), "table_tripID.csv")
tempdat<-merge(landings, trips, by=mergecol)
tempdat[tempdat$trip_id=="1 11 ACER + DULETES",]
names(trips)
tempdat<-merge(landings, trips, by=mergecol)
dim(tempdat)
dim(landings)
dim(trips)
19288+370
